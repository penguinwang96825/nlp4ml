{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import time\n",
    "import swifter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp4ml.preprocessing import clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cd86888ce04cb397be2d12d666f65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/31962 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for credit i cannot use cause they do n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>i love u take with u all the time in ur ! ! !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide : society now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "      <td>ate isz that youuu ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "      <td>to see nina turner on the airwaves trying to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "      <td>vandalised in in , condemns act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "      <td>thank you for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1      0   @user when a father is dysfunctional and is s...   \n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3      0                                bihday your majesty   \n",
       "3          4      0  #model   i love u take with u all the time in ...   \n",
       "4          5      0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...   \n",
       "31958  31959      0    to see nina turner on the airwaves trying to...   \n",
       "31959  31960      0  listening to sad songs on a monday morning otw...   \n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...   \n",
       "31961  31962      0                   thank you @user for you follow     \n",
       "\n",
       "                                             clean_tweet  \n",
       "0      when a father is dysfunctional and is so selfi...  \n",
       "1      thanks for credit i cannot use cause they do n...  \n",
       "2                                    bihday your majesty  \n",
       "3          i love u take with u all the time in ur ! ! !  \n",
       "4                               factsguide : society now  \n",
       "...                                                  ...  \n",
       "31957                               ate isz that youuu ?  \n",
       "31958  to see nina turner on the airwaves trying to w...  \n",
       "31959  listening to sad songs on a monday morning otw...  \n",
       "31960                    vandalised in in , condemns act  \n",
       "31961                           thank you for you follow  \n",
       "\n",
       "[31962 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_tweet\"] = df[\"tweet\"].swifter.apply(clean_tweet)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83038b90535340c8bef0be57f1ea87ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/31962 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet_tokenised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for credit i cannot use cause they do n...</td>\n",
       "      <td>[thanks, for, credit, i, cannot, use, cause, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>i love u take with u all the time in ur ! ! !</td>\n",
       "      <td>[i, love, u, take, with, u, all, the, time, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide : society now</td>\n",
       "      <td>[factsguide, society, now]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "      <td>ate isz that youuu ?</td>\n",
       "      <td>[ate, isz, that, youuu, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "      <td>to see nina turner on the airwaves trying to w...</td>\n",
       "      <td>[to, see, nina, turner, on, the, airwaves, try...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "      <td>[listening, to, sad, songs, on, a, monday, mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "      <td>vandalised in in , condemns act</td>\n",
       "      <td>[vandalised, in, in, condemns, act]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "      <td>thank you for you follow</td>\n",
       "      <td>[thank, you, for, you, follow]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1      0   @user when a father is dysfunctional and is s...   \n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3      0                                bihday your majesty   \n",
       "3          4      0  #model   i love u take with u all the time in ...   \n",
       "4          5      0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...   \n",
       "31958  31959      0    to see nina turner on the airwaves trying to...   \n",
       "31959  31960      0  listening to sad songs on a monday morning otw...   \n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...   \n",
       "31961  31962      0                   thank you @user for you follow     \n",
       "\n",
       "                                             clean_tweet  \\\n",
       "0      when a father is dysfunctional and is so selfi...   \n",
       "1      thanks for credit i cannot use cause they do n...   \n",
       "2                                    bihday your majesty   \n",
       "3          i love u take with u all the time in ur ! ! !   \n",
       "4                               factsguide : society now   \n",
       "...                                                  ...   \n",
       "31957                               ate isz that youuu ?   \n",
       "31958  to see nina turner on the airwaves trying to w...   \n",
       "31959  listening to sad songs on a monday morning otw...   \n",
       "31960                    vandalised in in , condemns act   \n",
       "31961                           thank you for you follow   \n",
       "\n",
       "                                   clean_tweet_tokenised  \n",
       "0      [when, a, father, is, dysfunctional, and, is, ...  \n",
       "1      [thanks, for, credit, i, cannot, use, cause, t...  \n",
       "2                                [bihday, your, majesty]  \n",
       "3      [i, love, u, take, with, u, all, the, time, in...  \n",
       "4                             [factsguide, society, now]  \n",
       "...                                                  ...  \n",
       "31957                          [ate, isz, that, youuu, ]  \n",
       "31958  [to, see, nina, turner, on, the, airwaves, try...  \n",
       "31959  [listening, to, sad, songs, on, a, monday, mor...  \n",
       "31960                [vandalised, in, in, condemns, act]  \n",
       "31961                     [thank, you, for, you, follow]  \n",
       "\n",
       "[31962 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_tweet_tokenised\"] = df[\"clean_tweet\"].swifter.apply(lambda x: re.split(r\"\\W+\", x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingVectorizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self):\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X, y)\n",
    "\n",
    "    def progressbar(self, iteration, prefix=\"\", size=50, file=sys.stdout):\n",
    "        count = len(iteration)\n",
    "        def show(t):\n",
    "            x = int(size*t/count)\n",
    "            # file.write(\"%s[%s%s] %i/%i\\r\" % (prefix, \"#\"*x, \".\"*(size-x), int(100*t/count), 100))\n",
    "            file.write(\"{}[{}{}] {}%\\r\".format(prefix, \"█\"*x, \".\"*(size-x), int(100*t/count)))\n",
    "            file.flush()\n",
    "        show(0)\n",
    "        for i, item in enumerate(iteration):\n",
    "            yield item\n",
    "            show(i+1)\n",
    "        file.write(\"\\n\")\n",
    "        file.flush()\n",
    "\n",
    "class SifEmbeddingVectorizer(EmbeddingVectorizer):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    word2vec: gensim.models.KeyedVectors()\n",
    "        Word2Vec: https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
    "        GloVe: https://nlp.stanford.edu/projects/glove/\n",
    "        FastText: https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "    smoothing_constant: float (default: 1e-3)\n",
    "        Default value of smoothing constant suggested in the paper is 0.001.\n",
    "        The range of a suggested in the paper: [1e−4, 1e−3]\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from gensim.scripts import glove2word2vec\n",
    "    >>> from gensim.models import KeyedVectors\n",
    "    >>> w2v_model = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "    >>> glove2word2vec(glove_input_file=r\"glove.840B.300d.txt\", word2vec_output_file=r\"gensim_glove_vectors.txt\")\n",
    "    >>> glove_model = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)\n",
    "    >>> embedding_dict = KeyedVectors.load_word2vec_format(r\"cc.en.300.vec\", binary=False)\n",
    "    >>> embedding_dict.save_word2vec_format(r\"cc.en.300.bin\", binary=True)\n",
    "    >>> ft_model = KeyedVectors.load_word2vec_format(\"cc.en.300.bin\", binary=True)\n",
    "    >>> vectoriser = SifEmbeddingVectorizer(word2vec=w2v_model)\n",
    "    >>> feature = vectoriser.fit_transform(df[\"text\"], None)\n",
    "    \"\"\"\n",
    "    def __init__(self, word2vec, smoothing_constant=1e-3):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = word2vec.vector_size\n",
    "        self.smoothing_constant = smoothing_constant\n",
    "        self.term_freq = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_list = [item for sublist in X for item in sublist]\n",
    "        term_freq = Counter(X_list)\n",
    "        total_len = sum(term_freq.values())\n",
    "        term_freq = [(term, term_freq[term]/total_len) for term, count in term_freq.items()]\n",
    "        self.term_freq = dict(term_freq)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        transformed_X = []\n",
    "        for doc in self.progressbar(X, prefix=\"SIF\"):\n",
    "            weighted_array = []\n",
    "            for term in doc:\n",
    "                if term in self.word2vec:\n",
    "                    # Compute smooth inverse frequency (SIF)\n",
    "                    weight = self.smoothing_constant / (self.smoothing_constant + self.term_freq.get(term, 0))\n",
    "                    weighted_term = self.word2vec[term] * weight\n",
    "                    weighted_array.append(weighted_term)\n",
    "            weighted_array = np.mean(weighted_array or [np.zeros(self.dim)], axis=0)\n",
    "            transformed_X.append(weighted_array)\n",
    "        transformed_X = np.array(transformed_X)\n",
    "\n",
    "        # Common component removal: remove the projections of the average vectors on their first singular vector\n",
    "        svd = TruncatedSVD(n_components=1, n_iter=20, random_state=0)\n",
    "        svd.fit(transformed_X)\n",
    "        pc = svd.components_\n",
    "        transformed_X = transformed_X - transformed_X.dot(pc.T).dot(pc)\n",
    "        return transformed_X\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"word2vec\": self.word2vec, \"smoothing_constant\": self.smoothing_constant}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format(r\"./embedding/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(df.clean_tweet_tokenised, \n",
    "                                                      df.label, \n",
    "                                                      test_size=0.2, \n",
    "                                                      stratify=df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIF[██████████████████████████████████████████████████] 100%\n",
      "SIF[████████████████████████████████████████████████..] 97%\r"
     ]
    }
   ],
   "source": [
    "tweet_list = df[\"clean_tweet_tokenised\"].values.tolist()\n",
    "vectoriser = SifEmbeddingVectorizer(word2vec=w2v_model)\n",
    "X_train_feature = vectoriser.fit_transform(X_train)\n",
    "X_valid_feature = vectoriser.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(cv=5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(cv=5)\n",
    "clf.fit(X_train_feature, y_train)\n",
    "y_valid_pred = clf.predict(X_valid_feature)\n",
    "metrics.classification_report(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
